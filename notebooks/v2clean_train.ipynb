{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "v2clean_sample_old.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGL1gD-DvtLj",
        "outputId": "cd6c7dcd-e827-4a1d-ff08-5c32fa68ac9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qUW9WRf-dYR",
        "outputId": "0ec3c193-d578-4a04-cc67-e231966582fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "!pip install -q efficientnet\n",
        "import math, re, os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "import tensorflow as tf\n",
        "import tensorflow_probability as tfp\n",
        "import tensorflow.keras.layers as L\n",
        "import tensorflow.keras.backend as K\n",
        "import efficientnet.tfkeras as efn\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "import random\n",
        "from sklearn.model_selection import GroupKFold\n",
        "import pickle\n",
        "# Detect hardware, return appropriate distribution strategy\n",
        "try:\n",
        "    # TPU detection. No parameters necessary if TPU_NAME environment variable is\n",
        "    # set: this is always the case on Kaggle.\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "    print('Running on TPU ', tpu.master())\n",
        "except ValueError:\n",
        "    tpu = None\n",
        "if tpu:\n",
        "    tf.config.experimental_connect_to_cluster(tpu)\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "else:\n",
        "    # Default distribution strategy in Tensorflow. Works on CPU and single GPU.\n",
        "    strategy = tf.distribute.get_strategy()\n",
        "print(\"REPLICAS: \", strategy.num_replicas_in_sync)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running on TPU  grpc://10.114.115.242:8470\n",
            "WARNING:tensorflow:TPU system grpc://10.114.115.242:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.114.115.242:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.114.115.242:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.114.115.242:8470\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4mZmnVB-qAA"
      },
      "source": [
        "AUTO = tf.data.experimental.AUTOTUNE\n",
        "IMAGE_SIZE = [512,512]\n",
        "EPOCHS = 2000\n",
        "BATCH_SIZE_PER_TPU = 8\n",
        "EFF_VER = 7\n",
        "EMB_SIZE=512\n",
        "BATCH_SIZE = BATCH_SIZE_PER_TPU * strategy.num_replicas_in_sync\n",
        "FOLDERNAME = 'v2clean_sample'\n",
        "DRIVE_DS_PATH = '/content/gdrive/My Drive/'+FOLDERNAME\n",
        "os.makedirs(DRIVE_DS_PATH,exist_ok=True)\n",
        "NUM_CLASSES = 81313\n",
        "EFNS = [efn.EfficientNetB0, efn.EfficientNetB1, efn.EfficientNetB2, efn.EfficientNetB3, \n",
        "        efn.EfficientNetB4, efn.EfficientNetB5, efn.EfficientNetB6,efn.EfficientNetB7]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRq9UMcv4sVD"
      },
      "source": [
        "train_16fold = pd.read_csv('/content/gdrive/My Drive/landmark/train_16fold.csv')\n",
        "from collections import Counter\n",
        "landmarkIdCounter = dict(Counter(train_16fold['clean_landmark_id']))\n",
        "train_16fold['counts'] = [landmarkIdCounter[x] for x in train_16fold['clean_landmark_id']]\n",
        "countIdList = []\n",
        "for key in sorted(landmarkIdCounter):\n",
        "    countIdList.append(landmarkIdCounter[key])\n",
        "scaleV = 1/ np.mean(1/np.log(np.array(train_16fold['counts'])))\n",
        "lossWeight = tf.constant(scaleV/np.log(np.array(countIdList)))\n",
        "lossWeight = tf.tile(tf.expand_dims(lossWeight,0),tf.constant([BATCH_SIZE_PER_TPU,1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJ4CLJSZRIlV"
      },
      "source": [
        "#GCS_DS_PATH = 'GCS private bucket path'\n",
        "TRAIN_GCS_PATH = GCS_DS_PATH + '/v2clean_tfrecord_train'\n",
        "TRAIN_FILENAMES = tf.io.gfile.glob(TRAIN_GCS_PATH + '/*.tfrec')\n",
        "VALID_GCS_PATH = GCS_DS_PATH + '/v2clean_tfrecord_valid'\n",
        "VALID_FILENAMES = tf.io.gfile.glob(VALID_GCS_PATH + '/*.tfrec')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSvyETqAKWJ1"
      },
      "source": [
        "def normalize_image(image):\n",
        "    image -= tf.constant([0.485 * 255, 0.456 * 255, 0.406 * 255])  # RGB\n",
        "    image /= tf.constant([0.229 * 255, 0.224 * 255, 0.225 * 255])  # RGB\n",
        "    return image\n",
        "def decode_image(image_data):\n",
        "    image = tf.image.decode_jpeg(image_data, channels=3)\n",
        "    image = tf.image.resize(image, IMAGE_SIZE)\n",
        "    image = normalize_image(image)\n",
        "    image = tf.reshape(image, [*IMAGE_SIZE, 3])\n",
        "    return image\n",
        "def img_aug(image, label):\n",
        "    img = tf.image.random_flip_left_right(image)\n",
        "    return img, label\n",
        "def read_labeled_tfrecord(example):\n",
        "    LABELED_TFREC_FORMAT = {\n",
        "        \"_bits\": tf.io.FixedLenFeature([], tf.string), # tf.string means bytestring\n",
        "        \"_class\": tf.io.FixedLenFeature([], tf.int64),  # shape [] means single element\n",
        "        '_id': tf.io.FixedLenFeature([], tf.string)\n",
        "    }\n",
        "    example = tf.io.parse_single_example(example, LABELED_TFREC_FORMAT)\n",
        "    image = decode_image(example['_bits'])\n",
        "    label = tf.cast(example['_class'],tf.int32)\n",
        "    return image, label\n",
        "\n",
        "def load_dataset(filenames, ordered=False):\n",
        "    ignore_order = tf.data.Options()\n",
        "    if not ordered:\n",
        "        ignore_order.experimental_deterministic = False # disable order,increase speed\n",
        "    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTO) # automatically interleaves reads from multiple files\n",
        "    dataset = dataset.with_options(ignore_order) # uses data as soon as it streams in, rather than in its original order\n",
        "    dataset = dataset.map(read_labeled_tfrecord, num_parallel_calls=AUTO)\n",
        "    return dataset\n",
        "\n",
        "def get_training_dataset():\n",
        "    dataset = load_dataset(TRAIN_FILENAMES,ordered=False)\n",
        "    dataset = dataset.repeat() # the training dataset must repeat for several epochs\n",
        "    dataset = dataset.map(img_aug, num_parallel_calls=AUTO)\n",
        "    dataset = dataset.batch(BATCH_SIZE)\n",
        "    dataset = dataset.prefetch(AUTO) # prefetch next batch while training (autotune prefetch buffer size)\n",
        "    return dataset\n",
        "\n",
        "def get_validation_dataset():\n",
        "    dataset = load_dataset(VALID_FILENAMES,ordered=True)\n",
        "    dataset = dataset.repeat() # the training dataset must repeat for several epochs\n",
        "    dataset = dataset.batch(BATCH_SIZE)\n",
        "    dataset = dataset.prefetch(AUTO) # prefetch next batch while training (autotune prefetch buffer size)\n",
        "    return dataset\n",
        "\n",
        "def count_data_items(filenames):\n",
        "    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n",
        "    return np.sum(n)\n",
        "    \n",
        "NUM_TRAINING_IMAGES = count_data_items(TRAIN_FILENAMES)\n",
        "NUM_VALIDATION_IMAGES = count_data_items(VALID_FILENAMES)\n",
        "print('Dataset: {} training images'.format(NUM_TRAINING_IMAGES))\n",
        "print('Dataset: {} validation images'.format(NUM_VALIDATION_IMAGES))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JaF69i92akLI"
      },
      "source": [
        "class ArcMarginProduct_v2(tf.keras.layers.Layer):\n",
        "    def __init__(self, num_classes):\n",
        "        super(ArcMarginProduct_v2, self).__init__()\n",
        "        self.num_classes= num_classes\n",
        "    def build(self, input_shape):\n",
        "        self.w = self.add_variable(\n",
        "            \"weights\", shape=[int(input_shape[-1]), self.num_classes])\n",
        "    def call(self, input):\n",
        "        cosine = tf.matmul(tf.nn.l2_normalize(input, axis=1), tf.nn.l2_normalize(self.w, axis=0))\n",
        "        return cosine"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRVjN7uffEl6"
      },
      "source": [
        "def getefn():\n",
        "    pretrained_model = EFNS[EFF_VER](weights=None, include_top=False ,input_shape=[*IMAGE_SIZE, 3])\n",
        "    pretrained_model.trainable = True\n",
        "    return pretrained_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sSOMg9lOaheI"
      },
      "source": [
        "def ArcFaceResNet():\n",
        "    x= inputs = tf.keras.Input([*IMAGE_SIZE, 3], name='input_image')\n",
        "    x = getefn()(x)\n",
        "    x = L.GlobalAveragePooling2D()(x)\n",
        "    x = L.Dense(EMB_SIZE, activation='swish')(x)\n",
        "    target = ArcMarginProduct_v2(NUM_CLASSES)(x)\n",
        "    return tf.keras.Model(inputs, target)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N03QSYmzVFrC"
      },
      "source": [
        "#references\n",
        "#https://arxiv.org/abs/1905.00292\n",
        "#https://github.com/taekwan-lee/adacos-tensorflow/blob/master/adacos.py\n",
        "class adacosLoss:\n",
        "    def __init__(self):\n",
        "        self.adacos_s = tf.math.sqrt(2.0) * tf.math.log(tf.cast(NUM_CLASSES - 1,tf.float32))\n",
        "        self.pi =  tf.constant(3.14159265358979323846)\n",
        "        self.theta_zero = self.pi/4\n",
        "        self.m = 0.5\n",
        "    def getLoss(self, labels, logits, mode):\n",
        "        mask = tf.one_hot(tf.cast(labels, tf.int32), depth = NUM_CLASSES)\n",
        "        theta = tf.math.acos(tf.clip_by_value(logits, -1.0 + 1e-7, 1.0 - 1e-7))\n",
        "        B_avg =tf.where(mask==1,tf.zeros_like(logits), tf.math.exp(self.adacos_s * logits))\n",
        "        B_avg = tf.reduce_mean(tf.reduce_sum(B_avg, axis=1), name='B_avg')\n",
        "        B_avg = tf.stop_gradient(B_avg)\n",
        "        theta_class = tf.gather_nd(theta, tf.stack([tf.range(tf.shape(labels)[0]), labels], axis=1),name='theta_class')\n",
        "        theta_med = tfp.stats.percentile(theta_class, q=50)\n",
        "        theta_med = tf.stop_gradient(theta_med)\n",
        "        self.adacos_s=(tf.math.log(B_avg) / tf.cos(tf.minimum(self.theta_zero, theta_med)))\n",
        "        output = tf.multiply(self.adacos_s, logits, name='adacos_logits')        \n",
        "        cce = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True,reduction=tf.keras.losses.Reduction.NONE)\n",
        "        if mode=='train':\n",
        "            loss = cce(labels, output, sample_weight = tf.gather_nd(lossWeight, tf.stack([tf.range(BATCH_SIZE_PER_TPU),labels], axis=1)))\n",
        "        else:\n",
        "            loss = cce(labels, output)\n",
        "        return loss   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umdmOUGZK6cx"
      },
      "source": [
        "with strategy.scope():\n",
        "    model = ArcFaceResNet()\n",
        "    optimizer = tf.keras.optimizers.SGD(1e-3, momentum=0.9,decay = 1e-5)\n",
        "    train_loss = tf.keras.metrics.Sum()\n",
        "    valid_loss = tf.keras.metrics.Sum()\n",
        "    def loss_fn(labels, predictions,mode='train'):\n",
        "        _adacosLoss = adacosLoss()\n",
        "        per_example_loss = _adacosLoss.getLoss(labels, predictions,mode)\n",
        "        return tf.nn.compute_average_loss(per_example_loss, global_batch_size= BATCH_SIZE)\n",
        "    model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h3ZhDpZuLLxR"
      },
      "source": [
        "STEPS_PER_TPU_CALL = NUM_TRAINING_IMAGES // BATCH_SIZE //4\n",
        "VALIDATION_STEPS_PER_TPU_CALL = NUM_VALIDATION_IMAGES // BATCH_SIZE\n",
        "@tf.function\n",
        "def train_step(data_iter):\n",
        "    def train_step_fn(images, labels):\n",
        "        with tf.GradientTape() as tape:\n",
        "            cosine = model(images)\n",
        "            loss = loss_fn(labels, cosine)\n",
        "        grads = tape.gradient(loss, model.trainable_variables)\n",
        "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "        #update metrics\n",
        "        train_loss.update_state(loss)\n",
        "    #this loop runs on the TPU\n",
        "    for _ in tf.range(STEPS_PER_TPU_CALL):\n",
        "        strategy.run(train_step_fn, next(data_iter))\n",
        "@tf.function\n",
        "def valid_step(data_iter):\n",
        "    def valid_step_fn(images, labels):\n",
        "        probabilities = model(images, training=False)\n",
        "        loss = loss_fn(labels, probabilities,'valid')\n",
        "        # update metrics\n",
        "        valid_loss.update_state(loss)\n",
        "    # this loop runs on the TPU\n",
        "    for _ in tf.range(VALIDATION_STEPS_PER_TPU_CALL):\n",
        "        strategy.run(valid_step_fn, next(data_iter))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PM2ib6haY4BQ"
      },
      "source": [
        "from collections import namedtuple\n",
        "train_dist_ds = strategy.experimental_distribute_dataset(get_training_dataset())\n",
        "valid_dist_ds = strategy.experimental_distribute_dataset(get_validation_dataset())\n",
        "print(\"Training steps per epoch:\", STEPS_PER_EPOCH, \"in increments of\", STEPS_PER_TPU_CALL)\n",
        "epoch = START_EPOCH\n",
        "train_data_iter = iter(train_dist_ds) # the training data iterator is repeated and it is not reset\n",
        "                                      # for each validation run (same as model.fit)\n",
        "valid_data_iter = iter(valid_dist_ds)\n",
        "while True:\n",
        "    train_step(train_data_iter)\n",
        "    print('|', end='', flush=True)\n",
        "    valid_step(valid_data_iter)\n",
        "    print('=', end='', flush=True)\n",
        "    trainLossV = train_loss.result().numpy()/STEPS_PER_TPU_CALL\n",
        "    print('\\nEPOCH {:d}/{:d}'.format(epoch+1, EPOCHS))\n",
        "    print('loss: {:0.4f}'.format(trainLossV),\n",
        "          'valid_loss : {:0.4f} '.format(valid_loss.result().numpy() / VALIDATION_STEPS_PER_TPU_CALL),\n",
        "          flush=True)\n",
        "    model.save_weights(os.path.join(DRIVE_DS_PATH, 'weights.epoch{:02d}.loss{:0.4f}.valid_loss{:0.4f}.hdf5').format(epoch+1, trainLossV,valid_loss.result().numpy() /VALIDATION_STEPS_PER_TPU_CALL))\n",
        "    epoch += 1\n",
        "    train_loss.reset_states()\n",
        "    valid_loss.reset_states()\n",
        "    if epoch >= EPOCHS:\n",
        "        break"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
