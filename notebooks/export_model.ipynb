{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "export_sample",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHNGf0GtODff",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "outputId": "9e76257a-acd7-4fca-9c24-03baf1ea1506"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ybh74B_NzVd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "a4af8aa6-0308-4077-fc9e-3397d97c3280"
      },
      "source": [
        "!pip install -q efficientnet\n",
        "import math, re, os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "import tensorflow as tf\n",
        "import tensorflow_probability as tfp\n",
        "import tensorflow.keras.layers as L\n",
        "import tensorflow.keras.backend as K\n",
        "import efficientnet.tfkeras as efn\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "import random\n",
        "from sklearn.model_selection import GroupKFold\n",
        "import pickle\n",
        "# Detect hardware, return appropriate distribution strategy\n",
        "try:\n",
        "    # TPU detection. No parameters necessary if TPU_NAME environment variable is\n",
        "    # set: this is always the case on Kaggle.\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "    print('Running on TPU ', tpu.master())\n",
        "except ValueError:\n",
        "    tpu = None\n",
        "if tpu:\n",
        "    tf.config.experimental_connect_to_cluster(tpu)\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "else:\n",
        "    # Default distribution strategy in Tensorflow. Works on CPU and single GPU.\n",
        "    strategy = tf.distribute.get_strategy()\n",
        "print(\"REPLICAS: \", strategy.num_replicas_in_sync)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |██████▌                         | 10kB 29.9MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 20kB 10.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 30kB 4.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 40kB 5.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 3.2MB/s \n",
            "\u001b[?25hREPLICAS:  1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GyRlgD51PKRa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EFNS = [efn.EfficientNetB0,efn.EfficientNetB1,efn.EfficientNetB2,efn.EfficientNetB3,\n",
        "        efn.EfficientNetB4,efn.EfficientNetB5,efn.EfficientNetB6,efn.EfficientNetB7]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tE4g8wg-PLXR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_model_v1(IMAGE_SIZE, NUM_CLASSES, EMB_SIZE, EFF_VER, order=0,weight_path=None):\n",
        "    class ArcMarginProduct_v2(tf.keras.layers.Layer):\n",
        "        def __init__(self, num_classes):\n",
        "            super(ArcMarginProduct_v2, self).__init__()\n",
        "            self.num_classes= num_classes\n",
        "        def build(self, input_shape):\n",
        "            self.w = self.add_variable(\n",
        "                \"weights\", shape=[int(input_shape[-1]), self.num_classes])\n",
        "        def call(self, input):\n",
        "            cosine = tf.matmul(tf.nn.l2_normalize(input, axis=1), tf.nn.l2_normalize(self.w, axis=0))\n",
        "            return cosine\n",
        "    def getefn():\n",
        "        pretrained_model = EFNS[EFF_VER](weights=None, include_top=False ,input_shape=[*IMAGE_SIZE, 3])\n",
        "        pretrained_model.trainable = True\n",
        "        return pretrained_model\n",
        "    def ArcFaceResNet():\n",
        "        x= inputs = tf.keras.Input([*IMAGE_SIZE, 3])\n",
        "        x = getefn()(x)\n",
        "        x = L.GlobalAveragePooling2D()(x)\n",
        "        x = L.Dense(EMB_SIZE, activation='swish')(x)\n",
        "        target = ArcMarginProduct_v2(NUM_CLASSES)(x)\n",
        "        model = tf.keras.Model(inputs, target)\n",
        "        model.get_layer('efficientnet-b'+str(EFF_VER))._name='efficientnet-b'+str(EFF_VER)+str(order)\n",
        "        return model\n",
        "    model = ArcFaceResNet()\n",
        "    model.summary()\n",
        "    if weight_path is not None:\n",
        "        model.load_weights(weight_path)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "frbgzF5zlppR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        },
        "outputId": "1f8fa120-384a-4378-f72d-f3fed958234f"
      },
      "source": [
        "#single model\n",
        "model = get_model_v1([640,640],203094,512,6,1,'/content/gdrive/My Drive/eff6_640_notclean_0.5_1.1931.hdf5')\n",
        "_model= tf.keras.Model(inputs= model.input, \n",
        "                       outputs =model.get_layer('dense').output)\n",
        "def export_model_v1(model, outdir):\n",
        "    @tf.function(input_signature=[\n",
        "        tf.TensorSpec(\n",
        "            shape=[None, None, 3],\n",
        "            dtype=tf.uint8,\n",
        "            name='input_image')\n",
        "    ])\n",
        "    def serving(input_image):\n",
        "        image = tf.image.resize(input_image, [640,640])\n",
        "        image -= tf.constant([0.485 * 255, 0.456 * 255, 0.406 * 255])  # RGB\n",
        "        image /= tf.constant([0.229 * 255, 0.224 * 255, 0.225 * 255])  # RGB\n",
        "        image = tf.reshape(image, [640,640,3])\n",
        "\n",
        "        outputs = model(image[tf.newaxis])\n",
        "        features = tf.math.l2_normalize(outputs[0])        \n",
        "        return {\n",
        "            'global_descriptor': tf.identity(features, name='global_descriptor')\n",
        "        }\n",
        "    tf.saved_model.save(\n",
        "    obj=model,\n",
        "    export_dir=outdir,\n",
        "    signatures={'serving_default': serving})\n",
        "export_model_v1(_model,'/content/gdrive/My Drive/landmark_export_model/eff6_640_notclean05_11931')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-4-38744144d572>:8: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.add_weight` method instead.\n",
            "Model: \"functional_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 640, 640, 3)]     0         \n",
            "_________________________________________________________________\n",
            "efficientnet-b61 (Functional (None, 20, 20, 2304)      40960136  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d (Gl (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               1180160   \n",
            "_________________________________________________________________\n",
            "arc_margin_product_v2 (ArcMa (None, 203094)            103984128 \n",
            "=================================================================\n",
            "Total params: 146,124,424\n",
            "Trainable params: 145,899,992\n",
            "Non-trainable params: 224,432\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFjgxqLccOS3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#ensemble\n",
        "model1 = get_model_v1([640,640],203094,512,7,1,'/content/gdrive/My Drive/eff7_640_notclean_0.5_1.1411.hdf5')\n",
        "model2 = get_model_v1([640,640],203094,512,6,2,'/content/gdrive/My Drive/eff6_640_notclean_0.5_1.1931.hdf5')\n",
        "model3 = get_model_v1([640,640],203094,512,7,3,'/content/gdrive/My Drive/landmark/eff7_512_ver2_10293_NotClean_0.5_640/shuffle_weights.epoch44.loss1.5736.valid_loss1.2554.hdf5')\n",
        "model4 = get_model_v1([512,512],203094,512,7,4,'/content/gdrive/My Drive/eff7_512_ver1_notclean0.5_1.2580.hdf5')\n",
        "_model= tf.keras.Model(inputs= [model1.input, \n",
        "                                model2.input,\n",
        "                                model3.input,\n",
        "                                model4.input,\n",
        "                                ],\n",
        "                       outputs =[model1.get_layer('dense').output,\n",
        "                                 model2.get_layer('dense_1').output,\n",
        "                                 model3.get_layer('dense_2').output,\n",
        "                                 model4.get_layer('dense_3').output,\n",
        "                                 ])\n",
        "def export_model_v1(model, outdir):\n",
        "    @tf.function(input_signature=[\n",
        "        tf.TensorSpec(\n",
        "            shape=[None, None, 3],\n",
        "            dtype=tf.uint8,\n",
        "            name='input_image')\n",
        "    ])\n",
        "    def serving(input_image):\n",
        "        image2 = tf.image.resize(input_image, [640,640])\n",
        "        image2 -= tf.constant([0.485 * 255, 0.456 * 255, 0.406 * 255])  # RGB\n",
        "        image2 /= tf.constant([0.229 * 255, 0.224 * 255, 0.225 * 255])  # RGB\n",
        "        image2 = tf.reshape(image2, [640,640,3])\n",
        "        image3 = tf.image.resize(input_image, [512,512])\n",
        "        image3 -= tf.constant([0.485 * 255, 0.456 * 255, 0.406 * 255])  # RGB\n",
        "        image3 /= tf.constant([0.229 * 255, 0.224 * 255, 0.225 * 255])  # RGB\n",
        "        image3 = tf.reshape(image3, [512,512,3])\n",
        "        outputs = model((image2[tf.newaxis],image2[tf.newaxis],image2[tf.newaxis],image3[tf.newaxis]))\n",
        "        output1 = tf.math.l2_normalize(outputs[0][0])\n",
        "        output2 = 0.8*tf.math.l2_normalize(outputs[1][0])\n",
        "        output3 = 0.55*tf.math.l2_normalize(outputs[2][0])\n",
        "        output4 = 0.5*tf.math.l2_normalize(outputs[3][0])\n",
        "        features =  tf.concat([output1,output2,output3, output4],axis=-1)\n",
        "        return {\n",
        "            'global_descriptor': tf.identity(features, name='global_descriptor')\n",
        "        }\n",
        "    tf.saved_model.save(\n",
        "    obj=model,\n",
        "    export_dir=outdir,\n",
        "    signatures={'serving_default': serving})\n",
        "export_model_v1(_model,'/content/gdrive/My Drive/landmark_export_model/0816_notclean05_640_776_512_7')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
